---
layout: post
title:  "信贷模型风控知识点-技术篇"
date:   2022-02-21
categories: 风控模型
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>


## ***前言***
自从进入风控领域以后，日常总会遇到稀奇古怪的问题，归根到底还是基础不牢固，因此应该时刻对平时遇到的问题作出总结，记录在博客中，方便自己回顾，同时保持学习的热情。本篇主要从**技术角度**分析信贷风控模型所需要注意的知识点。

![信贷风控](https://i.niupic.com/images/2022/02/22/9V8O.jpg)

## **数据分箱**
### **离散的优势**
(1) 离散后的特征对异常数据具有较强的鲁棒性。例如当年龄>50是1，否则为0，如果不进行上述离散化处理，一旦出现年龄为300则会对模型产生很大干扰。

(2) 逻辑回归属于广义线性模型，表达能力有限，将单变量离散化后可以给每个分段赋予单独的权重，相当于为模型引入了非线性，提升模型表达能力。

(3) 离散后可进行特征交叉，进一步增强非线性能力。举一个最简单的例子，两个特征：年龄和性别，可以组合成 年龄_性别 的一个新特征，比如$M_18$，$F_22$等等，然后再对这个特征做one hot编码，即可得到新的特征属性值（暴力交叉可能产生的稀疏性问题参考*FM*和*FFM*解决方案）

(4) 可以把缺失值作为一类带入模型考虑

(5) 可以所有变量运用到相似尺度上

(6) 运算速度更快

### **分箱方法**
有监督分箱：卡方分箱，Best-KS分箱

无监督分享：等频分箱，等距分箱，聚类分箱

（后期补充具体方法）

### **WOE，IV**
(1) 计算方法

$$WOE_i = \ln(\frac{py_i}{pn_i}) = ln(\frac{\frac{y_i}{y_T}}{\frac{n_i}{n_T}})$$

分别代表响应客户占比和未响应客户占比的比值

$$IV_i = (py_i-pn_i)*WOE_i$$

## **数据质量**
### **缺失率**
数据缺失作为一种状态，按照机制分为**完全随机缺失**（举例：一位老师丢失几张学生试卷，导致几位学生没有成绩。成绩的缺失与成绩本身变量无关，也与性别无关，是完全随机的），**随机缺失**（与其他变量有关，举例，统计学生信息时，体重缺失，一般来说，女生的体重缺失，与性别有关），**非随机缺失**（与变量本身有关，举例，统计收入数据时，一般缺失的是收入过高或过低）

(1) 使用均值，最小值，最大值，中位数(缺失率5%以下)，拉格朗日插值法，牛顿插值法等

(2) 作为一种状态（针对非随机缺失）

(3) 使用固定值或者临近值，例如某地工资标准是1000，可以作为补充值

(4) 回归法，使用该变量和其他与其有关的变量建立拟合关系来补充该值，随机森林法（类似回归法，适用于只有一个特征大量缺失的情况）

(5) 删除记录或者变量

### **集中度**
一般集中度较高的可以进行删除。

### **异常值**
这里异常值处理指的是针对单变量异常值进行处理，同时也简单提及金融风控异常检测的方法

(1) 作为缺失值处理

(2) 删除记录或者变量

异常值检测方法
> 基于**统计学**的方法：

> 3 $\sigma$ 法则，即均值上下3倍方差以外识别为异常；箱体图，即25%和75%分位点差为1IQR，小于Q1-1.5IRQ或者大于Q3+1.5IQR作为异常

> 基于**模型**的方法：

> oneclassSVM（超球面替代svm的超平面），autoencoder（正常样本进行模型训练，训练完，异常样本进入后输出时均方误差会比较大因而被识别），无监督学习包括IF（孤立森林，常用于金融交易欺诈监测）等

*孤立森林*：从数据集N条数据中均匀抽样n个，作为这颗树的样本，再随机选择一个特征，随机选择一个值进行二叉划分，持续下去到不可再分，记录路径长度。所有的树构建完成开始综合计算每棵树的结果，获得异常得分，如果异常得分接近 1，那么一定是异常点；如果异常得分远小于 0.5，那么一定不是异常点；如果异常得分所有点的得分都在 0.5 左右，那么样本中很可能不存在异常点。具体可以参考[该大神的文章](https://www.isolves.com/it/cxkf/sf/2019-09-25/5311.html)。

## **特征工程**
### **特征选择(逻辑回归常规过程)**
(1) 先进行前面的缺失率异常值集中度处理或者剔除部分特征

(2) 分箱，计算woe，IV，剔除合并无法保证单调性、单调性方向正确的特征，以及IV过小的特征

(3) 相关系数较高的，选择IV较高的特征

(4) 变量稳定性CSI检验，删除稳定性大于0.05的变量（可选）

(5) 通过逐步回归方法筛选最终如模变量（可去除多重共线性）

***若选择后特征仍然太多，可以使用PCA，LDA等降维方法进行降维操作。***

另外，使用逻辑回归变量显著性、xgb特征重要度也可以选择特征。xgb变量重要性排序主要有三个方法：

- Weight：变量在所有树中作为划分变量的次数
- Gain: 变量作为划分变量后的平均增益
- Coverage: 变量重要性使用了变量作为划分变量后对样本的覆盖度

### **特征衍生**
(1) 在金融风控领域，很多情况下是通过业务经验进行特征衍生，比如近12个月实还金额比发生减少的月数这种复杂指标，这些业界经验非常多，例如欺诈类的可以参考["这个博客"](https://zhuanlan.zhihu.com/p/375951458)

(2) 自动化特征工程，推荐系统的自动化特征工程方法较多，可参考["这里"](https://zhuanlan.zhihu.com/p/259583779)，金融风控领域已有尝试主要使用显示特征组合方式，例如DFS，通过遵循基本字段的关系链路，沿该链路通过数学函数创建最终特征（Python的Featuretools库可以很好地实现这种算法）。剩下的比如半显式的GBDT+LR，RF，隐式的FM（因子分解机），FFM等。

- **开发时间：** 完成特征工程代码耗时：手动10小时，自动1小时

- **生成特征数量：** 30个手动特征，1820个自动特征

- **相对于baseline的提升：** 65%（手动结果）vs 66%（自动化结果）

## **算法对比**
### **XGBOOST，GBDT，RF，LightGBM**

(算法推导部分于单独章节补充，本章参考["这里"](https://blog.csdn.net/yimingsilence/article/details/82193890))

(1) 一切基础，决策树(太基础的就不谈了，一棵树而已)
- ID3决策树中我们使用**信息增益**来指导分裂，其概念为得知a属性后使得样本集合不确定性减少的程度，即信息熵-条件熵。找到最大信息熵的那个特征进行分裂，然后对于每个分裂的子节点循环使用信息增益分裂。具体参考["这位朋友的分享"](https://zhuanlan.zhihu.com/p/26760551)。但是ID3算法拥有致命的问题，即该算法对可取值数目最多的属性有所偏好，因此引出C4.5算法
- C4.5决策树中我们使用**信息增益率**来指导分裂，改善了ID3的不足
- CART回归树，是一个二叉树，通过遍历变量和切分点，找到可以使平方损失函数最小的【变量，切分点】，划分区域后计算每个区域的平均值作为输出值，并且循环使用上述方法直到达到要求。分类树使用基尼系数

(2) RF,GBDT属于集成学习，继承多个基学习器的预测结果来改善单个学习器的泛化能力和鲁棒性。而XGBOOST和lightGBM是GBDT优秀的工程实现和改进。

> 随机森林，Bagging算法延伸

- 步骤为 (1)随机选择样本(**有放回**) (2)随机选择特征(**延伸点**) (3)构建决策树 (4) 随机森林投票
- 特征为 (1)不剪枝，回归任务平均法，分类任务投票法 (2)不用对其交叉验证，生长过程中对误差进行无偏估计(个学习器只是用了训练集中63.8%的样本)

> GBDT，Boosting算法延伸

- 传统Adaboost更新分类器权重和样本权重，如果样本被错误预测则加大权重，GBDT是不断拟合树的残差(**延伸点**)
- GBDT的树都是CART回归树，不论是分类还是回归任务。

> XGBOOST, GBDT延伸

- GBDT优化时仅用到一阶导，XGBOOST对函数进行二阶泰勒展开，同时可以自定义损失函数（只要函数一阶二阶可导）
- XGBOOST在代价函数中加入了正则项，用于控制模型的复杂度，正则项降低了模型的方差，降低过拟合
- 增加shrinkage，减小每棵树的影响力，为后面的树提供空间优化模型
- column subsampling，列特征抽样，防止过拟合，效果很好
- XGBOOST系数感知算法，可以自动处理有缺失值的样本
- **但是**，每轮迭代都需要遍历很多次数据，同时需要预排序，保存数据和数据顺序，空间消耗大

> LightGBM，对XGBOOST优化

- 牺牲部分精确度（实际上牺牲的不多），但是提升效率
- 使用histogram算法替代之前的pre—sorted算法，减小内存消耗
- 同时使用的还有Gradient-based One-Side Sampling（GOSS）梯度单边采样（小梯度样本得到训练），Exclusive Feature Bundling 独立特征合并（稀疏矩阵变成稠密矩阵），Leaf-wise (Best-first) Tree Growth （提高精度，虽然会增加过拟合可能，但是前面的操作都有天然正则化效果），这里参考["这个同学的分享"](https://zhuanlan.zhihu.com/p/38516467)

## **模型调优**
### **调参方式**
(1) 手动调参，详情参考["xgboost调参小结"](https://mp.weixin.qq.com/s?__biz=MzA3NDE4OTI5NQ==&mid=2247484502&idx=1&sn=aa8519321f1ef8ac8c85cdbe360d4d23&scene=21#wechat_redirect)

- 调参顺序影响调参结果，一般优先调整对模型影响比较大的参数
- 一般先n_estimators（300以下），subsample（50%），eta（0.01-0.2），另外还有些用于剪枝的参数例如gamma（每增加一片叶子就会被减去的惩罚项），另外还有些入maxdepth树最大深度等，但这两个通常用一个就行。

（2）其他调参工具

- 在算力支持的情况下，可以使用网格搜索，贝叶斯搜索等方法，暂时不展开。

### **其他优化工作**

(1) **自定义损失函数：** 保证损失函数二阶可导，通过评价函数最大化即可对模型参数求解，可根据业务指标对二者进行调整。

(2) **解决过拟合：** 正则化，随机森林，交叉验证，神经网络可以通过dropout，earlystopping等手段，数据扩增。

(3) **解决欠拟合：** 数据扩增，增加训练特征数量，使用天然过拟合模型如xgboost等，提高训练迭代次数，减少正则化参数。

(4) **解决欠拟合：** 数据扩增，增加训练特征数量，使用天然过拟合模型如xgboost等，提高训练迭代次数，减少正则化参数。

(5) **梯度下降和牛顿法：** 梯度下降是从当前位置负梯度方向以一定步长进行更新（批量，小批量和随机梯度下降），牛顿法二阶泰勒展开，最小化损失函数，收敛速度快。拟牛顿法对其作出改进。

## **模型评估**
### **评估指标**
(1) 准确率，所有预测正确的占总体比值

(2) 精确率，所有预测正且正确占预测为正的比例

(3) 召回率，所有预测为正占所有正样本的比例

(4) F1score

$$F1 = \frac{2*精确率*召回率}{精确率+召回率}$$

(5) ROC，受试者工作特征曲线，纵轴TPR(召回率)，横轴FPR(所有预测为负但错误的站所有负样本的比例)

(6) AUC，ROC线下面积

(7) Gini，绝对公平线和洛伦兹曲线（在评判分类模型的时候就是ROC曲线）的面积/绝对公平线以上面积的比例

(8) KS值，不同阈值下，TPR和FPR曲线的差值，表示模型的区分度

(9) CAP曲线，所有样本按照概率值降序排列，因此横轴是样本量，纵轴是正样本数量，理想状态是前面都是坏的，形成了Perfect Model，完全随机是Random Model，中间是Actual Model

(10) AR值，CAP曲线中，$\frac{Actual-Random}{Perfect-Random}$，用于评价模型效果

(11) PSI值，分数分档后，各个分数区间内样本占样本的占比是否有显著变化

$$PSI = \sum((Actual\%-Exp\%)*\ln(\frac{Actual\%}{Exp\%}))$$

## **风险定价**
### **RAROC**

这里列出平时工作上使用的RAROC计算逻辑作为风险定价的案例。

(1) 计算信用风险暴露相关性R（不同贷款计算方法不一样，根据PD来）

(2) 计算信用风险暴露的资本要求K（针对不良和非不良使用不同计算方式，用到R值）

(3) 资金成本zjcb，风险成本fxcb，管理成本glcb等，加起来称为总成本zcb

(4) 信用风险加权资产，或经济资本jjzb（用到K值）

(5) 损益金额syje（收益，或者利率计算）

(6) 交叉营销系数w

(7) 计算RAROC

$$RAROC = \frac{(syje(1-税率系数)-zcb)*w}{jjzb}$$

### **容忍度分析**

容忍度分析也有一套流程，根据业务种类和各行的业务执行情况可以使用不同的分析方法。这里提供一种思路：

> 还原核销，计算坏账额，计算vintage，计算资金成本，风险成本，管理成本，vintage纬度下损益率，同纬度决定mx+的逾期容忍度

附：[Vintage，滚动率，迁移率，坏账准备金](https://zhuanlan.zhihu.com/p/81027037/)

滚动率分析用于定义客户的好坏程度。Vintage分析用于确定合适的表现期。迁移率用于监控坏账的发展倾向和催收效果。



